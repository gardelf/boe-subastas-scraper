# üöÇ Gu√≠a de Despliegue en Railway

Esta gu√≠a te ayudar√° a desplegar el BOE Subastas Scraper en Railway paso a paso.

## Opci√≥n 1: Despliegue desde GitHub (Recomendado)

### Paso 1: Preparar el Repositorio

1. **Crea un repositorio en GitHub:**
   - Ve a [github.com/new](https://github.com/new)
   - Nombre: `boe-subastas-scraper`
   - Visibilidad: Privado (recomendado) o P√∫blico
   - No inicialices con README (ya tenemos uno)

2. **Sube el c√≥digo:**

```bash
cd boe-subastas-scraper

# Inicializar git (si no est√° inicializado)
git init

# Agregar archivos
git add .

# Commit inicial
git commit -m "Initial commit: BOE Subastas Scraper"

# Conectar con GitHub (reemplaza con tu URL)
git remote add origin https://github.com/TU-USUARIO/boe-subastas-scraper.git

# Subir c√≥digo
git branch -M main
git push -u origin main
```

### Paso 2: Crear Proyecto en Railway

1. **Ve a Railway:**
   - Accede a [railway.app](https://railway.app)
   - Inicia sesi√≥n con GitHub

2. **Crear nuevo proyecto:**
   - Click en "New Project"
   - Selecciona "Deploy from GitHub repo"
   - Autoriza Railway a acceder a tus repositorios
   - Selecciona `boe-subastas-scraper`

3. **Railway detectar√° autom√°ticamente:**
   - ‚úÖ Dockerfile
   - ‚úÖ railway.json
   - ‚úÖ Configuraci√≥n de build

### Paso 3: Configurar Variables de Entorno

En el dashboard de Railway, ve a tu servicio ‚Üí **Variables**:

**Variables Obligatorias:**

```env
NODE_ENV=production
PORT=3000
LOCALIDAD_FILTRO=Rivas Vaciamadrid
PROVINCIA_FILTRO=Madrid
SCRAPER_SCHEDULE=0 9 * * *
DATABASE_PATH=./data/subastas.db
HEADLESS=true
BROWSER_TIMEOUT=30000
LOG_LEVEL=info
```

**Variables Opcionales (para notificaciones por email):**

```env
EMAIL_NOTIFICATIONS=true
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=tu-email@gmail.com
SMTP_PASS=tu-contrase√±a-app
NOTIFY_EMAIL=destino@email.com
```

### Paso 4: Configurar Volumen para Persistencia

**IMPORTANTE:** Sin volumen, perder√°s la base de datos al reiniciar.

1. En Railway, ve a tu servicio
2. Click en **Settings** ‚Üí **Volumes**
3. Click en **+ New Volume**
4. Configuraci√≥n:
   - **Mount Path:** `/app/data`
   - **Size:** 1 GB (suficiente)
5. Click en **Add**
6. Railway redesplegar√° autom√°ticamente

### Paso 5: Desplegar

1. Railway iniciar√° el despliegue autom√°ticamente
2. Monitorea los logs en la pesta√±a **Deployments**
3. Espera a ver: `‚úÖ Build successful`
4. Luego: `‚úÖ Deployment successful`

### Paso 6: Verificar Funcionamiento

1. **Obtener URL p√∫blica:**
   - Ve a **Settings** ‚Üí **Networking**
   - Click en **Generate Domain**
   - Se generar√° una URL como: `https://tu-app.up.railway.app`

2. **Probar la API:**
   - Visita: `https://tu-app.up.railway.app/health`
   - Deber√≠as ver: `{"status":"ok",...}`

3. **Ver la interfaz:**
   - Visita: `https://tu-app.up.railway.app/`
   - Ver√°s la p√°gina de documentaci√≥n de la API

4. **Ejecutar scraper manualmente:**
   ```bash
   curl -X POST https://tu-app.up.railway.app/api/scrape
   ```

5. **Ver logs en tiempo real:**
   - En Railway, pesta√±a **Logs**
   - Busca mensajes como: `Scraper ejecutado exitosamente`

---

## Opci√≥n 2: Despliegue con Railway CLI

### Paso 1: Instalar Railway CLI

```bash
npm install -g @railway/cli
```

### Paso 2: Login

```bash
railway login
```

Se abrir√° tu navegador para autenticarte.

### Paso 3: Inicializar Proyecto

```bash
cd boe-subastas-scraper
railway init
```

Selecciona:
- "Create a new project"
- Nombre: `boe-subastas-scraper`

### Paso 4: Configurar Variables

```bash
# Variables obligatorias
railway variables set NODE_ENV=production
railway variables set PORT=3000
railway variables set LOCALIDAD_FILTRO="Rivas Vaciamadrid"
railway variables set PROVINCIA_FILTRO="Madrid"
railway variables set SCRAPER_SCHEDULE="0 9 * * *"
railway variables set DATABASE_PATH="./data/subastas.db"
railway variables set HEADLESS=true
railway variables set BROWSER_TIMEOUT=30000
railway variables set LOG_LEVEL=info

# Variables opcionales (email)
railway variables set EMAIL_NOTIFICATIONS=true
railway variables set SMTP_HOST=smtp.gmail.com
railway variables set SMTP_PORT=587
railway variables set SMTP_SECURE=false
railway variables set SMTP_USER="tu-email@gmail.com"
railway variables set SMTP_PASS="tu-contrase√±a-app"
railway variables set NOTIFY_EMAIL="destino@email.com"
```

### Paso 5: Crear Volumen

```bash
railway volume create --name subastas-data --mount-path /app/data
```

### Paso 6: Desplegar

```bash
railway up
```

Railway construir√° y desplegar√° tu aplicaci√≥n.

### Paso 7: Ver Logs

```bash
railway logs
```

### Paso 8: Abrir en Navegador

```bash
railway open
```

---

## Configuraci√≥n Avanzada

### Programaci√≥n Personalizada

Edita `SCRAPER_SCHEDULE` para cambiar la frecuencia:

```bash
# Cada 6 horas
railway variables set SCRAPER_SCHEDULE="0 */6 * * *"

# Dos veces al d√≠a (9 AM y 6 PM)
railway variables set SCRAPER_SCHEDULE="0 9,18 * * *"

# Solo d√≠as laborables a las 9 AM
railway variables set SCRAPER_SCHEDULE="0 9 * * 1-5"
```

### M√∫ltiples Localidades

Para monitorear m√∫ltiples localidades, despliega m√∫ltiples instancias:

```bash
# Instancia 1: Rivas Vaciamadrid
railway variables set LOCALIDAD_FILTRO="Rivas Vaciamadrid"

# Instancia 2: Madrid (crear nuevo proyecto)
railway init
railway variables set LOCALIDAD_FILTRO="Madrid"
```

### Health Checks

Railway usa el endpoint `/health` para verificar que el servicio est√° activo:

- **Intervalo:** Cada 60 segundos
- **Timeout:** 100 segundos
- **Pol√≠tica de reinicio:** ON_FAILURE (hasta 10 intentos)

Configurado en `railway.json`.

---

## Monitoreo y Mantenimiento

### Ver Ejecuciones del Scraper

```bash
# Desde la API
curl https://tu-app.up.railway.app/api/runs
```

### Ver Subastas Encontradas

```bash
# Listar todas
curl https://tu-app.up.railway.app/api/subastas

# Ver una espec√≠fica
curl https://tu-app.up.railway.app/api/subastas/SUB-JA-2016-13134
```

### Ejecutar Scraper Manualmente

```bash
curl -X POST https://tu-app.up.railway.app/api/scrape
```

### Descargar Base de Datos

Railway no permite acceso directo a vol√∫menes, pero puedes:

1. Agregar endpoint para exportar datos
2. Usar las exportaciones JSON/Excel autom√°ticas
3. Consultar v√≠a API

### Ver Logs en Tiempo Real

**Opci√≥n 1: Dashboard Web**
- Ve a railway.app ‚Üí Tu proyecto ‚Üí Logs

**Opci√≥n 2: CLI**
```bash
railway logs --follow
```

---

## Troubleshooting

### ‚ùå Build Failed

**Error com√∫n:** "Cannot find module 'playwright'"

**Soluci√≥n:**
```bash
# Verifica que package.json tenga playwright
# Redespliega
railway up --detach
```

### ‚ùå Deployment Crashed

**Error com√∫n:** "Out of memory"

**Soluci√≥n:**
1. Reduce la frecuencia del scraper
2. Considera plan de pago con m√°s RAM
3. Optimiza `BROWSER_TIMEOUT`

### ‚ùå Database Locked

**Error com√∫n:** "database is locked"

**Soluci√≥n:**
1. Aseg√∫rate de tener volumen configurado
2. Reinicia el servicio:
   ```bash
   railway restart
   ```

### ‚ùå No se ejecuta el scraper

**Verificar:**
1. Logs: `railway logs`
2. Variables: `railway variables`
3. Zona horaria del cron (Europe/Madrid)

### ‚ùå Email no se env√≠a

**Verificar:**
1. `EMAIL_NOTIFICATIONS=true`
2. Contrase√±a de aplicaci√≥n de Gmail (no contrase√±a normal)
3. Logs para errores SMTP

---

## Costos Estimados

### Plan Gratuito (Hobby)
- **Incluye:** $5 de cr√©dito/mes
- **L√≠mites:**
  - 512 MB RAM
  - 1 GB disco
  - 100 GB transferencia
- **Suficiente para:** Scraper diario de Rivas Vaciamadrid

### Plan de Pago (Developer)
- **Costo:** $5/mes base + uso
- **Incluye:** $5 de cr√©dito
- **L√≠mites:** M√°s flexibles
- **Recomendado si:** M√∫ltiples localidades o frecuencia alta

### Optimizaci√≥n de Costos

1. **Reduce frecuencia:** `0 9 * * *` (solo 1 vez al d√≠a)
2. **Usa volumen peque√±o:** 1 GB es suficiente
3. **Headless mode:** `HEADLESS=true` (usa menos RAM)
4. **Monitorea uso:** Dashboard de Railway

---

## Comandos √ötiles Railway CLI

```bash
# Ver estado del servicio
railway status

# Ver variables configuradas
railway variables

# Abrir dashboard web
railway open

# Conectar a shell del contenedor
railway shell

# Ver m√©tricas
railway metrics

# Eliminar proyecto
railway delete
```

---

## Siguiente Paso: Automatizaci√≥n Completa

Una vez desplegado, el scraper:

1. ‚úÖ Se ejecutar√° autom√°ticamente seg√∫n `SCRAPER_SCHEDULE`
2. ‚úÖ Guardar√° datos en SQLite (persistente con volumen)
3. ‚úÖ Exportar√° a JSON y Excel
4. ‚úÖ Enviar√° emails si hay nuevas subastas (si est√° configurado)
5. ‚úÖ Estar√° disponible v√≠a API REST

**¬°Tu scraper est√° listo para funcionar 24/7!** üéâ

---

## Recursos Adicionales

- [Documentaci√≥n Railway](https://docs.railway.app)
- [Playwright Docs](https://playwright.dev)
- [Node-cron Syntax](https://www.npmjs.com/package/node-cron)
- [BOE Subastas](https://subastas.boe.es)

---

**¬øProblemas?** Revisa los logs primero: `railway logs`
